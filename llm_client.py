# llm_client.py

import os
import openai
from dotenv import load_dotenv
from prompt_templates import THINKING_STRATEGIES
from sentence_transformers import SentenceTransformer, util

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

class LLMClient:
    """
    ä¸€ä¸ªä¸å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰APIäº¤äº’çš„å®¢æˆ·ç«¯ã€‚
    å®ƒå°è£…äº†APIè°ƒç”¨ã€æ–‡æœ¬ç”Ÿæˆä»¥åŠæ›´å¤æ‚çš„æ€è€ƒç­–ç•¥ï¼ˆå¦‚åæ€å’Œæ·±åŒ–ï¼‰ã€‚
    """
    def __init__(self):
        """
        åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼ŒåŠ è½½APIå¯†é’¥å¹¶è®¾ç½®OpenAIå®¢æˆ·ç«¯ã€‚
        åŒæ—¶åŠ è½½ç”¨äºæ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—çš„æ¨¡å‹ã€‚
        """
        self.api_key = os.getenv("KIM_API_KEY")
        if not self.api_key:
            raise ValueError("æœªåœ¨.envæ–‡ä»¶ä¸­æ‰¾åˆ°KIM_API_KEYï¼Œè¯·æ£€æŸ¥ã€‚")
        
        try:
            self.client = openai.OpenAI(
                api_key=self.api_key,
                base_url="https://api.moonshot.cn/v1",
            )
            # 'all-MiniLM-L6-v2' æ˜¯ä¸€ä¸ªè½»é‡çº§ä¸”é«˜æ•ˆçš„æ¨¡å‹ï¼Œé€‚åˆæœ¬åœ°è®¡ç®—ç›¸ä¼¼åº¦
            self.similarity_model = SentenceTransformer('all-MiniLM-L6-v2')
            print("LLMClient åˆå§‹åŒ–æˆåŠŸï¼")
        except Exception as e:
            print(f"LLM å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def _check_convergence(self, answer1: str, answer2: str, threshold: float = 0.98) -> bool:
        """
        é€šè¿‡è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„è¯­ä¹‰ç›¸ä¼¼åº¦æ¥æ£€æŸ¥æ€è€ƒè¿‡ç¨‹æ˜¯å¦æ”¶æ•›ã€‚
        å½“æ–°æ—§ç­”æ¡ˆçš„ç›¸ä¼¼åº¦è¶…è¿‡é˜ˆå€¼æ—¶ï¼Œè®¤ä¸ºç­”æ¡ˆå·²ç»ç¨³å®šï¼Œå¯ä»¥åœæ­¢è¿­ä»£ã€‚
        """
        # å°†æ–‡æœ¬ç¼–ç ä¸ºå‘é‡è¡¨ç¤º
        embeddings = self.similarity_model.encode([answer1, answer2], convert_to_tensor=True)
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        cosine_sim = util.pytorch_cos_sim(embeddings[0], embeddings[1])
        print(f"æ”¶æ•›æ£€æŸ¥ï¼šå‰åä¸¤æ¬¡ç­”æ¡ˆçš„ç›¸ä¼¼åº¦ä¸º {cosine_sim.item():.4f}")
        return cosine_sim.item() > threshold

    def generate_text(self, prompt: str, max_tokens: int = 2048) -> str:
        """
        è°ƒç”¨LLM APIç”Ÿæˆæ–‡æœ¬çš„åŸºç¡€æ–¹æ³•ã€‚
        å¢åŠ äº† max_tokens å‚æ•°ä»¥æ§åˆ¶å•æ¬¡è¾“å‡ºçš„é•¿åº¦ï¼Œé˜²æ­¢è¢«æˆªæ–­ã€‚
        """
        print(f"æ­£åœ¨è°ƒç”¨Kimi API (max_tokens={max_tokens}): {prompt[:50]}...")
        try:
            response = self.client.chat.completions.create(
                model="moonshot-v1-8k",  # ä½¿ç”¨Kimiçš„8kæ¨¡å‹
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,         # è¾ƒä½çš„æ¸©åº¦ä½¿è¾“å‡ºæ›´å…·ç¡®å®šæ€§
                max_tokens=max_tokens    # æ§åˆ¶è¾“å‡ºé•¿åº¦
            )
            result = response.choices[0].message.content
            return result.strip()
        except Exception as e:
            print(f"è°ƒç”¨ Kimi API æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return f"Kimi API è°ƒç”¨å¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯ï¼š\n\n{str(e)}"

    def generate_with_reflection(self, prompt: str, strategy_name: str, max_iterations: int = 3) -> dict:
        """
        ä½¿ç”¨â€œè¿­ä»£åæ€â€ç±»ç­–ç•¥ç”Ÿæˆç­”æ¡ˆï¼ˆå¦‚è‡ªæˆ‘åæ€ã€å¯¹æŠ—å¼æ€è€ƒï¼‰ã€‚
        è¯¥æ–¹æ³•ä¼šè¿”å›ä¸€ä¸ªåŒ…å«æœ€ç»ˆç­”æ¡ˆå’Œè¯¦ç»†æ€è€ƒå†å²çš„å­—å…¸ã€‚
        """
        if strategy_name not in THINKING_STRATEGIES or THINKING_STRATEGIES[strategy_name]['type'] != 'iterative':
            raise ValueError(f"ç­–ç•¥ '{strategy_name}' ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„è¿­ä»£ç­–ç•¥ã€‚")
        
        strategy = THINKING_STRATEGIES[strategy_name]
        history = []
        
        # ç”Ÿæˆåˆç‰ˆç­”æ¡ˆï¼Œå¯ä»¥ç»™è¾ƒå¤šçš„token
        initial_answer = self.generate_text(prompt, max_tokens=2048)
        history.append({"type": "ğŸ“ åˆç‰ˆç­”æ¡ˆ", "content": initial_answer})
        current_answer = initial_answer

        for i in range(max_iterations):
            print(f"åæ€è¿‡ç¨‹ï¼šæ­£åœ¨è¿›è¡Œç¬¬ {i+1}/{max_iterations} è½®...")
            
            # ç”Ÿæˆæ‰¹åˆ¤/åæ€ï¼Œè¿™éƒ¨åˆ†å†…å®¹ä¸éœ€è¦å¤ªé•¿ï¼Œç²¾ç®€å³å¯ï¼ŒèŠ‚çœtoken
            critique_prompt = strategy["critique"].format(prompt=prompt, current_answer=current_answer)
            critique = self.generate_text(critique_prompt, max_tokens=512) 
            history.append({"type": f"ğŸ¤” ç¬¬ {i+1} è½®åæ€", "content": critique})

            # ç”Ÿæˆä¼˜åŒ–åçš„ç­”æ¡ˆï¼Œéœ€è¦å®Œæ•´å†…å®¹ï¼Œç»™è¶³token
            refinement_prompt = strategy["refinement"].format(prompt=prompt, current_answer=current_answer, critique=critique)
            refined_answer = self.generate_text(refinement_prompt, max_tokens=2048)
            
            # æ£€æŸ¥ç­”æ¡ˆæ˜¯å¦æ”¶æ•›
            if self._check_convergence(current_answer, refined_answer):
                print(f"æ€è€ƒå·²åœ¨ç¬¬ {i+1} è½®æ”¶æ•›ã€‚")
                history.append({"type": f"âœ¨ ä¿®æ­£ç‰ˆç­”æ¡ˆ #{i+1} (å·²æ”¶æ•›)", "content": "ç­”æ¡ˆå·²ç¨³å®šï¼Œç”Ÿæˆæœ€ç»ˆç‰ˆæœ¬ã€‚"})
                current_answer = refined_answer
                break

            history.append({"type": f"âœ¨ ä¿®æ­£ç‰ˆç­”æ¡ˆ #{i+1}", "content": "å·²æ ¹æ®åæ€ç”Ÿæˆæ–°ç‰ˆæœ¬ã€‚"})
            current_answer = refined_answer
        else: # for-else å¾ªç¯æ­£å¸¸ç»“æŸæ—¶æ‰§è¡Œ
             history.append({"type": "âœ… æ€è€ƒå®Œæˆ", "content": f"å·²è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° {max_iterations}ã€‚"})

        # è¿”å›åŒ…å«æœ€ç»ˆç­”æ¡ˆå’Œå†å²è®°å½•çš„å­—å…¸
        return {"final_answer": current_answer, "history": history}

    def generate_with_deepening(self, prompt: str, strategy_name: str) -> dict:
        """
        ä½¿ç”¨â€œæµæ°´çº¿å¼â€ç­–ç•¥ç”Ÿæˆç­”æ¡ˆï¼ˆå¦‚åˆ†æ­¥éª¤æ·±åŒ–ï¼‰ã€‚
        è¯¥æ–¹æ³•ä¼šæŒ‰é¡ºåºæ‰§è¡Œç­–ç•¥ä¸­çš„æ¯ä¸€æ­¥ï¼Œå¹¶è¿”å›æœ€ç»ˆç»“æœå’Œè¿‡ç¨‹å†å²ã€‚
        """
        if strategy_name not in THINKING_STRATEGIES or THINKING_STRATEGIES[strategy_name]['type'] != 'pipeline':
            raise ValueError(f"ç­–ç•¥ '{strategy_name}' ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„æµæ°´çº¿ç­–ç•¥ã€‚")

        strategy = THINKING_STRATEGIES[strategy_name]
        history = []

        # --- ç¬¬1æ­¥: å¿«é€Ÿæ¦‚è§ˆ ---
        print("æ·±åŒ–è¿‡ç¨‹ï¼šæ­£åœ¨æ‰§è¡Œç¬¬1æ­¥ - å¿«é€Ÿæ¦‚è§ˆ...")
        prompt_step1 = strategy['step1_overview'].format(prompt=prompt)
        overview = self.generate_text(prompt_step1, max_tokens=512) # æ¦‚è§ˆä¸éœ€è¦å¤ªé•¿
        history.append({"type": "â¡ï¸ ç¬¬ä¸€æ­¥ï¼šå¿«é€Ÿæ¦‚è§ˆ", "content": overview})

        # --- ç¬¬2æ­¥: è¯¦ç»†åˆ†æ ---
        print("æ·±åŒ–è¿‡ç¨‹ï¼šæ­£åœ¨æ‰§è¡Œç¬¬2æ­¥ - è¯¦ç»†åˆ†æ...")
        prompt_step2 = strategy['step2_analysis'].format(prompt=prompt, overview=overview)
        detailed_analysis = self.generate_text(prompt_step2, max_tokens=1500) # åˆ†æéƒ¨åˆ†å¯ä»¥é•¿ä¸€äº›
        history.append({"type": "â¡ï¸ ç¬¬äºŒæ­¥ï¼šè¯¦ç»†åˆ†æ", "content": detailed_analysis})

        # --- ç¬¬3æ­¥: è¡¥å……å®Œå–„ï¼Œç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ ---
        print("æ·±åŒ–è¿‡ç¨‹ï¼šæ­£åœ¨æ‰§è¡Œç¬¬3æ­¥ - è¡¥å……å®Œå–„...")
        prompt_step3 = strategy['step3_refine'].format(prompt=prompt, detailed_analysis=detailed_analysis)
        final_answer = self.generate_text(prompt_step3, max_tokens=2048) # æœ€ç»ˆç­”æ¡ˆéœ€è¦å®Œæ•´
        history.append({"type": "âœ… ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ", "content": "å·²æ•´åˆæ‰€æœ‰åˆ†æï¼Œç”Ÿæˆæœ€ç»ˆç‰ˆæœ¬ã€‚"})

        # è¿”å›åŒ…å«æœ€ç»ˆç­”æ¡ˆå’Œå†å²è®°å½•çš„å­—å…¸
        return {"final_answer": final_answer, "history": history}

