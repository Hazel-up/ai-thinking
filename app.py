# app.py

import streamlit as st
from llm_client import LLMClient
from prompt_templates import THINKING_STRATEGIES

@st.cache_resource
def init_llm_client():
    """
    åˆå§‹åŒ–LLMClientã€‚
    ä½¿ç”¨ @st.cache_resource è£…é¥°å™¨å¯ä»¥ç¡®ä¿åœ¨æ•´ä¸ªåº”ç”¨ç”Ÿå‘½å‘¨æœŸä¸­ï¼Œ
    LLMClientåªè¢«åˆ›å»ºä¸€æ¬¡ï¼Œé¿å…é‡å¤åŠ è½½æ¨¡å‹å’ŒAPIé…ç½®ã€‚
    """
    try:
        client = LLMClient()
        return client, None
    except Exception as e:
        # å¦‚æœåˆå§‹åŒ–å¤±è´¥ï¼ˆä¾‹å¦‚ï¼Œæ‰¾ä¸åˆ°APIå¯†é’¥ï¼‰ï¼Œåˆ™è¿”å›é”™è¯¯ä¿¡æ¯
        return None, str(e)

def main():
    """
    Streamlitåº”ç”¨çš„ä¸»å‡½æ•°ã€‚
    """
    # --- é¡µé¢åŸºç¡€è®¾ç½® ---
    st.set_page_config(
        page_title="æ€è€ƒæ·±åº¦å¯¹æ¯”å®éªŒå¹³å°", 
        page_icon="ğŸ’¡", 
        layout="wide"
    )
    st.title("ğŸ’¡ AIæ€è€ƒæ·±åº¦å¯¹æ¯”å®éªŒå¹³å°")
    st.markdown("é€šè¿‡å¯¹æ¯” **å•æ¬¡ç›´æ¥å›ç­”** ä¸ **å¤šç§è¿­ä»£/æ·±åŒ–ç­–ç•¥**ï¼Œè§‚å¯ŸAIå¦‚ä½•é€æ­¥ä¼˜åŒ–ç­”æ¡ˆã€‚")
    st.markdown("---")

    # --- åˆå§‹åŒ–å®¢æˆ·ç«¯ ---
    llm_client, error = init_llm_client()
    if error:
        st.error(f"LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {error}")
        st.info("è¯·ç¡®ä¿ä½ çš„é¡¹ç›®æ ¹ç›®å½•ä¸‹æœ‰ `.env` æ–‡ä»¶ï¼Œå¹¶ä¸”å…¶ä¸­å®šä¹‰äº† `KIM_API_KEY`ã€‚")
        st.info("åŒæ—¶ï¼Œè¯·æ£€æŸ¥ç›¸å…³ä¾èµ–åº“æ˜¯å¦å·²å®‰è£…: `pip install streamlit openai python-dotenv sentence-transformers`")
        return # åˆå§‹åŒ–å¤±è´¥æ—¶ï¼Œç»ˆæ­¢åº”ç”¨æ‰§è¡Œ

    # --- ä¾§è¾¹æ é…ç½® ---
    with st.sidebar:
        st.header("âš™ï¸ å®éªŒå‚æ•°é…ç½®")
        
        # ä»ç­–ç•¥åº“ä¸­æå–åç§°ç”¨äºä¸‹æ‹‰èœå•æ˜¾ç¤º
        strategy_options = {key: value["name"] for key, value in THINKING_STRATEGIES.items()}
        selected_strategy_key = st.selectbox(
            "é€‰æ‹©â€œåå¤æ€è€ƒâ€çš„ç­–ç•¥:",
            options=list(strategy_options.keys()),
            # format_func ç”¨äºå®šä¹‰ä¸‹æ‹‰èœå•ä¸­æ¯ä¸ªé€‰é¡¹çš„æ˜¾ç¤ºæ–‡æœ¬
            format_func=lambda key: strategy_options[key]
        )

        # æ ¹æ®é€‰æ‹©çš„ç­–ç•¥ï¼Œå†³å®šæ˜¯å¦æ˜¾ç¤ºâ€œæœ€å¤§åæ€è½®æ¬¡â€æ»‘å—
        selected_strategy_info = THINKING_STRATEGIES[selected_strategy_key]
        max_iterations = 0
        if selected_strategy_info.get("type") == "iterative":
            max_iterations = st.slider(
                "æœ€å¤§åæ€è½®æ¬¡:",
                min_value=1, max_value=5, value=2, step=1,
                help="è®¾ç½®å¾ªç¯æ€è€ƒçš„æœ€å¤§æ¬¡æ•°ã€‚å½“ç­”æ¡ˆå‰åå˜åŒ–ä¸å¤§æ—¶ï¼Œå¯èƒ½ä¼šæå‰â€œæ”¶æ•›â€å¹¶åœæ­¢ã€‚"
            )

    # --- ä¸»ç•Œé¢ ---
    prompt = st.text_area(
        "è¯·è¾“å…¥æ‚¨æƒ³è®©AIæ€è€ƒçš„é—®é¢˜ï¼š", 
        height=100, 
        placeholder="ä¾‹å¦‚ï¼šå¦‚ä½•æ‰èƒ½æœ‰æ•ˆåœ°å­¦ä¹ ä¸€é—¨æ–°çš„å¤–è¯­ï¼Ÿ"
    )

    # åˆ›å»ºå·¦å³ä¸¤ä¸ªå¸ƒå±€åˆ—
    col1, col2 = st.columns(2)

    with col1:
        st.header("ğŸš€ å•æ¬¡æ€è€ƒ")
        # ä¸ºâ€œå•æ¬¡æ€è€ƒâ€çš„è¾“å‡ºåˆ›å»ºä¸€ä¸ªå ä½ç¬¦
        single_pass_output = st.empty()

    with col2:
        st.header(f"ğŸ”„ {strategy_options[selected_strategy_key]}")
        # ä¸ºâ€œåå¤æ€è€ƒâ€çš„æœ€ç»ˆç­”æ¡ˆåˆ›å»ºä¸€ä¸ªå ä½ç¬¦
        reflective_output = st.empty()
        # ä¸ºâ€œåå¤æ€è€ƒâ€çš„æ€è€ƒè¿‡ç¨‹ï¼ˆst.statusï¼‰åˆ›å»ºä¸€ä¸ªå ä½ç¬¦
        status_placeholder = st.empty()

    # â€œå¼€å§‹æ€è€ƒâ€æŒ‰é’®
    if st.button("å¼€å§‹æ€è€ƒ", type="primary", use_container_width=True):
        if not prompt:
            st.warning("è¯·è¾“å…¥é—®é¢˜åå†å¼€å§‹æ€è€ƒï¼")
        else:
            # æ¸…ç©ºæ‰€æœ‰è¾“å‡ºåŒºåŸŸï¼Œå‡†å¤‡æ˜¾ç¤ºæ–°ç»“æœ
            single_pass_output.empty()
            reflective_output.empty()
            status_placeholder.empty()

            # --- 1. æ‰§è¡Œå•æ¬¡æ€è€ƒ ---
            with col1:
                with st.spinner("æ­£åœ¨è¿›è¡Œå•æ¬¡æ€è€ƒ..."):
                    single_response = llm_client.generate_text(prompt, max_tokens=2048)
                    single_pass_output.markdown(single_response)

            # --- 2. æ‰§è¡Œåå¤æ€è€ƒ ---
            with col2:
                spinner_text = f"æ­£åœ¨ä½¿ç”¨â€œ{strategy_options[selected_strategy_key]}â€ç­–ç•¥è¿›è¡Œæ€è€ƒ..."
                # ä½¿ç”¨ st.status æ¥åŒ…è£¹å¹¶å±•ç¤ºæ€è€ƒè¿‡ç¨‹
                with status_placeholder.status(spinner_text, expanded=True) as status:
                    result = {}
                    # æ ¹æ®ç­–ç•¥ç±»å‹è°ƒç”¨ä¸åŒçš„åç«¯æ–¹æ³•
                    if selected_strategy_info.get("type") == "iterative":
                        result = llm_client.generate_with_reflection(
                            prompt,
                            strategy_name=selected_strategy_key,
                            max_iterations=max_iterations
                        )
                    elif selected_strategy_info.get("type") == "pipeline":
                        result = llm_client.generate_with_deepening(
                            prompt,
                            strategy_name=selected_strategy_key
                        )
                    
                    # åœ¨ status ç»„ä»¶å†…éƒ¨ï¼Œæ¸²æŸ“æ€è€ƒå†å²è®°å½•
                    for step in result.get("history", []):
                        st.write(f"**{step['type']}**")
                        st.info(step['content'])
                    
                    # æ€è€ƒç»“æŸåï¼Œæ›´æ–°statusçŠ¶æ€ä¸ºå®Œæˆï¼Œå¹¶é»˜è®¤æŠ˜å 
                    status.update(label="æ€è€ƒå®Œæˆ!", state="complete", expanded=False)

                # åœ¨ä¸»ç•Œé¢ä¸Šï¼Œåªæ¸²æŸ“æœ€ç»ˆçš„ç­”æ¡ˆ
                final_answer = result.get("final_answer", "æŠ±æ­‰ï¼Œæœªèƒ½ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆã€‚")
                reflective_output.markdown(final_answer)

# å½“è¯¥è„šæœ¬ä½œä¸ºä¸»ç¨‹åºè¿è¡Œæ—¶ï¼Œæ‰§è¡Œmainå‡½æ•°
if __name__ == "__main__":
    main()
